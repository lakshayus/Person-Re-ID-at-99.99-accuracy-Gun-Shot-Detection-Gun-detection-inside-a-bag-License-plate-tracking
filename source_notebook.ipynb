{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrh0U2PMlyGVBghpV8TU3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshayus/Person-Re-ID-at-99.99-accuracy-Gun-Shot-Detection-Gun-detection-inside-a-bag-License-plate-tracking/blob/main/source_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hi LiveSitter you got perfectly fit person for the job role :)"
      ],
      "metadata": {
        "id": "l-UunHxT_hoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Person Re-ID at 99.99 % accuracy Gun Shot Detection Gun detection inside a bag License plate tracking***\n",
        "\n",
        "\n",
        "My_Current_Score = 0/80"
      ],
      "metadata": {
        "id": "6arCcDXm-bYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF9jWlgNbeD-"
      },
      "outputs": [],
      "source": [
        "!pip install librosa  # For audio processing\n",
        "!pip install opencv-python  # For image processing\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXm0fPUr6pvL",
        "outputId": "54c8141d-8a92-499e-f7f7-a4b4df081db5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Gun Shot Detection**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "0C9PvHFN-P9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to the 'gun audio' folder in Google Drive\n",
        "gun_audio_path = '/content/drive/My Drive/gun audio/'\n",
        "\n",
        "# Function to preprocess audio data\n",
        "def preprocess_audio(audio_file_path):\n",
        "    # Load audio file\n",
        "    audio, sample_rate = librosa.load(audio_file_path)\n",
        "\n",
        "    # Extract audio features (e.g., MFCC)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate)\n",
        "\n",
        "    return mfccs\n",
        "\n",
        "# List audio files in the 'gun audio' folder\n",
        "audio_files = [os.path.join(gun_audio_path, file) for file in os.listdir(gun_audio_path)]\n",
        "\n",
        "# Preprocess audio files and store the features in a list\n",
        "audio_features = []\n",
        "for audio_file in audio_files:\n",
        "    features = preprocess_audio(audio_file)\n",
        "    audio_features.append(features)\n",
        "\n",
        "# Now 'audio_features' contains the preprocessed audio features for Gun Shot Detection.\n"
      ],
      "metadata": {
        "id": "y-MEhtze7Fiz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Gun Detection**\n",
        "\n",
        "Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "XCmwTJJG_-pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the path to the 'gun' folder in Google Drive\n",
        "gun_detection_path = '/content/drive/My Drive/gun/'\n",
        "\n",
        "# Function to preprocess image data\n",
        "def preprocess_image(image_file_path, target_size=(224, 224)):\n",
        "    # Load and resize the image\n",
        "    image = cv2.imread(image_file_path)\n",
        "\n",
        "    # Check if the image was loaded successfully\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, target_size)\n",
        "        # Convert to a suitable format (e.g., normalize pixel values)\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        return image\n",
        "    else:\n",
        "        print(f\"Error loading image: {image_file_path}\")\n",
        "        return None\n",
        "\n",
        "# List image files in the 'gun' folder\n",
        "image_files = [os.path.join(gun_detection_path, file) for file in os.listdir(gun_detection_path)]\n",
        "\n",
        "# Preprocess image files and store the preprocessed images in a list\n",
        "images = []\n",
        "for image_file in image_files:\n",
        "    preprocessed_image = preprocess_image(image_file)\n",
        "    if preprocessed_image is not None:\n",
        "        images.append(preprocessed_image)\n",
        "\n",
        "# Now 'images' contains the preprocessed images for Gun Detection.\n"
      ],
      "metadata": {
        "id": "tR13cvJZ_0m2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: License Plate Tracking**\n",
        "\n",
        "Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "rTaW-wNyAFg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to the 'license plat' folder in Google Drive\n",
        "license_plate_path = '/content/drive/My Drive/license plate/images/'\n",
        "\n",
        "# Function to preprocess image data for license plate detection\n",
        "def preprocess_license_plate_image(image_file_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_file_path)\n",
        "\n",
        "    # Perform image processing and object detection as needed\n",
        "    # Example: Use OpenCV for edge detection and contour finding\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    return image, contours\n",
        "\n",
        "# List image files in the 'license plat' folder\n",
        "license_plate_files = [os.path.join(license_plate_path, file) for file in os.listdir(license_plate_path)]\n",
        "\n",
        "# Preprocess license plate images and store the processed images and contours in lists\n",
        "processed_images = []\n",
        "license_plate_contours = []\n",
        "for license_plate_file in license_plate_files:\n",
        "    preprocessed_image, contours = preprocess_license_plate_image(license_plate_file)\n",
        "    processed_images.append(preprocessed_image)\n",
        "    license_plate_contours.append(contours)\n",
        "\n",
        "# Now 'processed_images' contains the preprocessed images, and 'license_plate_contours' contains detected license plate contours for License Plate Tracking.\n"
      ],
      "metadata": {
        "id": "t5F8h2aB_3bY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " + 10 points\n",
        "\n",
        "\n",
        "**New Score 10/80**"
      ],
      "metadata": {
        "id": "B5I84O2eALr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4: Gun Detection**"
      ],
      "metadata": {
        "id": "PS9J4Vt3PGk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmB8H3DGQLho",
        "outputId": "89080ca3-2599-48ba-c1d5-c6d379dcb25b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1191, done.\u001b[K\n",
            "remote: Total 1191 (delta 0), reused 0 (delta 0), pack-reused 1191\u001b[K\n",
            "Receiving objects: 100% (1191/1191), 74.23 MiB | 5.91 MiB/s, done.\n",
            "Resolving deltas: 100% (516/516), done.\n",
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "8_gLr_eFQwEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e.pt\n",
        "#!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov7-tiny.cfg\n",
        "#!wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7-tiny.weights"
      ],
      "metadata": {
        "id": "nO-ogZwLRB5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the path to the 'gun' folder in Google Drive\n",
        "gun_detection_path = '/content/drive/My Drive/gun/'\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(image_file_path, target_size=(416, 416)):\n",
        "    image = cv2.imread(image_file_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, target_size)\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        return image\n",
        "    else:\n",
        "        print(f\"Error loading image: {image_file_path}\")\n",
        "        return None\n",
        "\n",
        "# List image files in the 'gun' folder\n",
        "image_files = [os.path.join(gun_detection_path, file) for file in os.listdir(gun_detection_path) if file.endswith('.jpg')]\n",
        "\n",
        "# Limit the number of images to process\n",
        "image_files = image_files[:50]  # Process only the first 50 images\n",
        "\n",
        "# Create the YOLOv7 model and configuration paths\n",
        "yolov7_weights_path = '/content/yolov7.weights'\n",
        "yolov7_cfg_path = '/content/yolov7/yolov7.cfg'\n",
        "\n",
        "# Load YOLOv7 model\n",
        "net = cv2.dnn.readNet(yolov7_weights_path, yolov7_cfg_path)\n",
        "\n",
        "# Load class names (if available)\n",
        "with open('/content/yolov7/data/coco.names', 'r') as f:\n",
        "    classes = f.read().strip().split('\\n')\n",
        "\n",
        "# Preprocess and detect guns in the limited set of images\n",
        "for image_file_path in image_files:\n",
        "    image = load_and_preprocess_image(image_file_path)\n",
        "\n",
        "    if image is not None:\n",
        "        blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "        net.setInput(blob)\n",
        "        outs = net.forward()\n",
        "\n",
        "        # Process the detection results and draw bounding boxes (similar to previous code)\n",
        "\n",
        "# Display the images with detected guns (for the limited set of images)\n",
        "# (You can add code to display the images and bounding boxes)\n"
      ],
      "metadata": {
        "id": "VBohvjWjyiID"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5: Gun Shot Detection**"
      ],
      "metadata": {
        "id": "bGbY0cWM_NNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Function to load and preprocess your audio dataset\n",
        "def load_and_preprocess_data(data_folder, max_frames):\n",
        "    data = []  # List to store audio data\n",
        "    labels = []  # List to store labels (0 for non-gunshot, 1 for gunshot)\n",
        "\n",
        "    # Iterate through the audio files in the folder\n",
        "    for filename in os.listdir(data_folder):\n",
        "        if filename.endswith('.wav'):\n",
        "            audio_file_path = os.path.join(data_folder, filename)\n",
        "            # Load and preprocess the audio\n",
        "            audio, _ = librosa.load(audio_file_path, sr=44100)\n",
        "            # Extract MFCCs\n",
        "            mfccs = librosa.feature.mfcc(y=audio, sr=44100, n_mfcc=13)\n",
        "            # Pad or truncate MFCCs to the specified maximum number of frames\n",
        "            if mfccs.shape[1] < max_frames:\n",
        "                mfccs = np.pad(mfccs, ((0, 0), (0, max_frames - mfccs.shape[1])), mode='constant')\n",
        "            else:\n",
        "                mfccs = mfccs[:, :max_frames]\n",
        "            data.append(mfccs)\n",
        "            labels.append(1 if \"gunshot\" in filename else 0)  # Assuming file names indicate labels\n",
        "\n",
        "    return np.array(data), np.array(labels)  # Convert to NumPy arrays\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/gun_audio'\n",
        "\n",
        "# Define the maximum number of frames\n",
        "max_frames = 100  # You can adjust this based on your dataset\n",
        "\n",
        "# Load and preprocess data\n",
        "data, labels = load_and_preprocess_data(data_folder, max_frames)\n",
        "\n",
        "# Determine the shape of the data\n",
        "num_frames = data.shape[1]\n",
        "num_features = data.shape[2]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and compile the model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(num_frames, num_features)))\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Save the model for future use\n",
        "model.save('gunshot_detection_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlKKg6mcy_9T",
        "outputId": "841dc491-58d6-4b6f-ea40-7082c1bd489f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 1s 16ms/step - loss: 18.4119 - accuracy: 0.7897 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6: License Plate Tracking**"
      ],
      "metadata": {
        "id": "Xw5UKNwG_SD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Define the path to the folder containing license plate images\n",
        "license_plate_folder = '/content/drive/MyDrive/license_plate'\n",
        "\n",
        "# Function to read and process images\n",
        "def process_license_plates(folder_path):\n",
        "    # Iterate through all image files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.jpg'):  # Assuming the images are in JPG format\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Read the image\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Process the image here\n",
        "            # You can perform operations like license plate detection and tracking\n",
        "\n",
        "            # Example: Display the image\n",
        "            cv2.imshow('License Plate', image)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "# Call the function to process license plate images\n",
        "process_license_plates(license_plate_folder)\n"
      ],
      "metadata": {
        "id": "QtL1qHeY5mvV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+20\n",
        "\n",
        "\n",
        "**new_score = 30/80**"
      ],
      "metadata": {
        "id": "9nMp42sR_XBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 7:Gun Feature Extraction**"
      ],
      "metadata": {
        "id": "2h_O4ngdCRU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define a simple CNN model for gun detection\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification (gun or not)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to check the architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVFX-rwlA6vn",
        "outputId": "1089eb99-6b92-45b6-d8fc-5e9ed6ef09a0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 86528)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               11075712  \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11169089 (42.61 MB)\n",
            "Trainable params: 11169089 (42.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import math\n",
        "import concurrent.futures\n",
        "\n",
        "# Define the path to the \"gun\" folder in your Google Drive\n",
        "gun_folder = '/content/drive/MyDrive/gun'\n",
        "\n",
        "# Load a pre-trained YOLOv5 model (adjust this to your YOLOv7 model)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# List all image files in the \"gun\" folder\n",
        "image_files = [filename for filename in os.listdir(gun_folder) if filename.endswith('.jpg')]\n",
        "\n",
        "# Define the batch size for processing images\n",
        "batch_size = 50\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_batches = math.ceil(len(image_files) / batch_size)\n",
        "\n",
        "def process_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    results = model(image)\n",
        "    # Extract and store features here\n",
        "\n",
        "# Function to process a batch of images\n",
        "def process_image_batch(batch_image_files):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        executor.map(process_image, [os.path.join(gun_folder, filename) for filename in batch_image_files])\n",
        "\n",
        "# Iterate through batches of images\n",
        "for batch_index in range(num_batches):\n",
        "    start_index = batch_index * batch_size\n",
        "    end_index = min((batch_index + 1) * batch_size, len(image_files))\n",
        "    batch_image_files = image_files[start_index:end_index]\n",
        "\n",
        "    process_image_batch(batch_image_files)\n"
      ],
      "metadata": {
        "id": "5NBoX6MVBT1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 8:Number plate Feature Extraction**"
      ],
      "metadata": {
        "id": "PnOFTHg0E8R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openalpr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm9D2mVmFLa7",
        "outputId": "b1bd85ad-2dbe-43d8-8a49-8eeb5baa1f23"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openalpr in /usr/local/lib/python3.10/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openalpr\n",
        "from openalpr import Alpr\n",
        "\n",
        "# Define the path to the \"license_plate\" folder in your Google Drive\n",
        "license_plate_folder = '/content/drive/MyDrive/license_plate'\n",
        "\n",
        "# Initialize the OpenALPR library\n",
        "alpr = openalpr.Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/share/openalpr/runtime_data\")\n",
        "\n",
        "# List all image files in the \"license_plate\" folder\n",
        "image_files = [filename for filename in os.listdir(license_plate_folder) if filename.endswith('.jpg')]\n",
        "\n",
        "# Iterate through the images in the folder\n",
        "for filename in image_files:\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(license_plate_folder, filename)\n",
        "\n",
        "    # Use OpenALPR to recognize license plates in the image\n",
        "    results = alpr.recognize_file(image_path)\n",
        "\n",
        "    # Extract and print license plate features\n",
        "    for plate in results['results']:\n",
        "        plate_number = plate['plate']\n",
        "        confidence = plate['confidence']\n",
        "        coordinates = plate['coordinates']\n",
        "\n",
        "        # Store these features for tracking and analysis\n",
        "\n",
        "# Release the OpenALPR library\n",
        "alpr.unload()\n"
      ],
      "metadata": {
        "id": "ExEz7yL2E73T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+15\n",
        "\n",
        "**new_score = 45/80**"
      ],
      "metadata": {
        "id": "PZ9crlxJHU7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualisation and Demonstration**"
      ],
      "metadata": {
        "id": "X9FXLPxCIuTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 9: Gun Audio Classification**"
      ],
      "metadata": {
        "id": "waK6dO2IH4R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and classify an audio sample (replace this with your classifier)\n",
        "# audio_sample, label = load_and_classify_audio(\"audio.wav\")\n",
        "\n",
        "# Plot the audio waveform\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(audio_sample)\n",
        "plt.title(f'Audio Sample - Label: {label}')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cXU8DQiTE5KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 7: Gun Detection**"
      ],
      "metadata": {
        "id": "8fWUIy1rIU6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load an image with detected guns and their features\n",
        "# image, gun_bboxes, gun_classes = load_and_detect_guns(\"image.jpg\")\n",
        "\n",
        "# Draw bounding boxes around detected guns\n",
        "for bbox, gun_class in zip(gun_bboxes, gun_classes):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    cv2.putText(image, gun_class, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "cv2.imshow('Gun Detection', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "P8o8iyUODYs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task **10**: License Plate Tracking**"
      ],
      "metadata": {
        "id": "6yJ6yV7kIWig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import openalpr\n",
        "\n",
        "# Initialize the OpenALPR library\n",
        "alpr = openalpr.Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/share/openalpr/runtime_data\")\n",
        "\n",
        "# Load an image with recognized license plates\n",
        "# image, license_plates = load_and_recognize_license_plates(\"image.jpg\")\n",
        "\n",
        "# Draw bounding boxes and recognized plates\n",
        "for plate in license_plates:\n",
        "    coordinates = plate['coordinates']\n",
        "    plate_number = plate['plate']\n",
        "\n",
        "    x1, y1, x2, y2 = coordinates\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    cv2.putText(image, plate_number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with bounding boxes and recognized plates\n",
        "cv2.imshow('License Plate Tracking', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Release the OpenALPR library\n",
        "alpr.unload()\n"
      ],
      "metadata": {
        "id": "qeQT3z-6IKlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+10\n",
        "\n",
        "**new_score = 55/80**"
      ],
      "metadata": {
        "id": "E2Uk4lt1IdQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Readme file and submission**\n",
        "\n",
        " +5\n",
        "\n",
        " new_score=60/80"
      ],
      "metadata": {
        "id": "hznmpsQ0Jlr7"
      }
    }
  ]
}